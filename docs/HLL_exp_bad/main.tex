\documentclass{IEEEtran}
\usepackage{graphicx}
\usepackage{array}
\usepackage{url}
\usepackage{hyperref}
\usepackage{xspace}

%% TODO NOTES

\usepackage{xcolor}
\definecolor{oxygenorange}{HTML}{FFDD00}
\usepackage[color=oxygenorange]{todonotes}
\newcommand{\mathilde}[1]{\todo[inline]{\textbf{Mathilde:} #1}\xspace}
\newcommand{\kenny}[1]{\todo[inline]{\textbf{Kenny:} #1}\xspace}

\title{HyperLogLog: Exponentially Bad in Adversarial Settings}
\author{Mathilde Raynal, Kenneth G. Paterson\\
\vspace{3mm}
Department of Computer Science, ETH Zurich\\
{\tt mraynal@student.ethz.ch, kenny.paterson@inf.ethz.ch}}

\begin{document}

\maketitle

\IEEEtitleabstractindextext{%
\begin{abstract}
Computing the count of distinct elements in massive data sets is a common task but naive approaches are memory-expensive. The HyperLogLog (HLL) algorithm (Flajolet \emph{et al.}, 2007) estimates a data stream's cardinality while using significantly less memory than a naive approach at the cost of some accuracy. This trade-off makes the HLL algorithm very attractive for a wide range of applications such as database management and network monitoring, where an exact count may not be needed. Recently, the HLL algorithm has started to be proposed for use in scenarios where the inputs may be adversarially generated, for example detection of network scanning attacks. This prompts an examination of the performance of the HLL algorithm in the face of adversarial inputs. In this cautionary note, we show that in such a setting, the HLL algorithm's estimate of cardinality can be exponentially bad: when an adversary has access to the internals of the HLL algorithm and has some flexibility in choosing what inputs will be recorded, it can manipulate the cardinality estimate to be exponentially smaller than the true cardinality.
\end{abstract}
}

\IEEEdisplaynontitleabstractindextext

\section{Introduction}
Naive approaches to computing the cardinality of a big data set, such as sorting the elements or simply maintaining the set of unique elements seen, are impractical at scale. The HyperLogLog algorithm (HLL henceforth)~\cite{hll} is today the most widely used cardinality estimator. It is increasingly used in settings where adversaries may have  incentives to manipulate the estimate made by the algorithm. For example,~\cite{portscanhll} proposes its use for detecting network scanning attacks, while Facebook engineers have reported~\cite{fbhll} that they use HLL for estimating the number of active users. These applications demand a careful evaluation of the performance of HLL under adversarial input.

Very recently, Reviriego and Ting~\cite{hllvuln} initiated work in this direction, showing that in specific attack settings, the cardinality estimate made by HLL could be modified through input selection. In this paper, we present a complete analysis of HLL in adversarial setting, considering more realistic attack scenarios and giving more powerful attacks than~\cite{hllvuln}. In particular, we show that with only modest knowledge of the HLL internals and a moderate amount of computation, an adversary with sufficient flexibility in the choice of inputs can make the HLL cardinality estimate exponentially smaller than the true cardinality (e.g.\ constant instead of $O(2^t)$ where $t$ is th number of bits of flexibility in the input).

The rest of the paper is organised as follows. Section~\ref{sec:overview} gives an overview of the HyperLogLog algorithm. Section~\ref{sec:attacks} presents our different adversarial models. There, we also give attacks and evaluate their impacts under the different adversarial models. Section~\ref{sec:conclusions} provides our conclusions and some ideas for future work.



\section{Overview of HLL}\label{sec:overview}
\subsection{The Algorithm}
HLL~\cite{hll} is a streaming algorithm based on the key observation that, for a stream of randomly distributed values represented as bit-strings of some fixed length, if we observe a value with the maximum of $k$ leading zero-bits, then the cardinality of the stream (i.e.\ the number of distinct values it contains) is likely to be on the order of $2^{k+1}$. In practice, to ensure a uniform distribution, the stream values are first processed by a hash function $h$ before the leading bits are inspected. So to estimate the cardinality of a stream, we need only store a representation of $k$, the length of the largest observed string of leading zero-bits for numbers in the stream. This provides a very compact mechanism for estimating the stream cardinality -- if the true cardinality is $N$, then just $\log\log(N)$ bits are needed to store the estimate.

This simple approach suffers from large variance in the estimation. In order to improve the estimate, we can use many estimators in parallel instead of one, and average the results. Each estimate is stored in its own bucket. The collection of buckets is referred to as the HLL \emph{sketch}. To map a value $x$ to one of $2^n$ buckets, \cite{loglog} suggests using the first $n$ bits of $h(x)$ as a bucket index, and then computing the longest sequence of leading zero bits on the remaining $\ell$ bits of $h(x)$ (so that the output length of $h(\cdot)$ is $n+\ell$). Estimators from all buckets are averaged using the harmonic mean and scaled by a constant $\alpha$, where $\alpha$ is empirically computed to correct a systematic multiplicative bias. As result, HLL is able to estimate cardinalities greater than $10^9$ with a typical standard error of 2\%, using only 1.5 kB of memory~\cite{hll}.

An interesting property of HLL is that it supports merging in a lossless way. To combine two buckets at index $i$ in two different HLL instances, take the maximum of the two bucket entries and assign that to the matching bucket $i$ in the merged HLL sketch. Such a simple set union operation allows easy parallelisation of operations among multiple machines independently, provided they use the same hash function and the same number of buckets.

\subsection{Applications}
For completeness and motivation, we provide examples of concrete uses of HLL:
\begin{itemize}
    \item Cardinality estimation provides a significantly faster way for Facebook to compute statistics on their users. They use HLL to find out how many distinct people visited their website in the past week~\cite{fbhll}.
    \item HLL has been proposed as a solution to detecting Denial-of-Service attacks~\cite{portscanhll} (this paper actually uses a variation on HLL called \emph{sliding HLL}~\cite{slidinghll} which estimates the cardinality over a moving time window). Specifically, HLL is used to count how many different ports are used as destination port over all packets received, as an attempt to identify when a port scan attack is underway.
    \item HLL has been implemented in network soft-switches to approximate the number of distinct packets in traffic flows and overcome the switch resource limits~\cite{flexswitch}. The number of unique flows traversing a switch can then be used to provide a better congestion control protocol.
\end{itemize}

Regardless of the sensitivity of the above examples, none of the relevant papers are clear about their threat model, especially for the HLL component.  They are all potentially vulnerable to the attacks we present below.
%By not assessing the risks involved with the presence of an adversary targeting the HLL sketch, they may allow an attack like the one we present, breaking down the whole solution.

\subsection{Related Work}

The work of~\cite{cardestprivacy} studies the privacy properties of HLL in two different attack scenarios, referred to as \emph{insider} and \emph{external}. The attack target of~\cite{cardestprivacy} is different from ours, being concerned with loss of privacy, whereas we care about cardinality estimation. It is argued in~\cite{cardestprivacy} that HLL can be used by organisations to store and process location data, which is inherently sensitive, so losing privacy would leak users' locations and potentially cause great harm. In Section~\ref{sec:attacks} we will discuss the two attack scenarios from~\cite{cardestprivacy} in more detail. In particular, we will show that an attacker who can insert items into the HLL and who can access the HLL cardinality estimate (via typical APIs in HLL implementations) as permitted in the external scenario can actually realise the same attacks as the insider attacker can, at least insofar as cardinality estimate manipulation is concerned.

In~\cite{hllvuln}, Reviriego and Ting exploit a vulnerability of HLL to manipulate the cardinality estimate, leading to a five-fold reduction in the estimate compared to the true cardinality. They use an attack model that we consider to be quite artificial, since it gives the attacker the ability to test whether inserting an item \emph{would} increase the cardinality estimate, without actually having to insert the item. See further discussion in Section~\ref{sec:attacks}.

Both~\cite{cardestprivacy,hllvuln} propose mitigations using a salted sketch, either as replacement (but at the cost of losing mergeability) or in addition to an unsalted sketch (inducing a memory overhead).
%This might not be a convenient solution for some applications, they thus encourage further research.

\section{HLL in Adversarial Settings}\label{sec:attacks}

This section presents different adversarial settings and corresponding attacks that manipulate the HLL cardinality estimate. The adversary's goal is to reduce the estimate as much as possible, since this would cause more damage when  considering the above-mentioned applications of HLL. It is easy to modify our attack strategies for an adversary who instead wishes to artificially inflate the HLL estimate given a limited input capability. We also analyze the impact on the HLL cardinality estimate and the computational effort required.

Throughout, we assume the adversary has the ability to vary the contents of free fields in the input strings which will be inserted into the stream of values. For example it can manipulate IPID and other header fields in the context of IP packets. This enables the adversary to control the output of hash function $h$ and flexibly choose which items will be inserted into the HLL sketch, and in which buckets.

\subsection{Adversarial Setting}
We model four distinct adversarial scenarios based on the adversary's knowledge and capabilities. For all of them, we assume that the sketch already contains some existing data from honest users to simulate a real-life setting. Among the scenarios, the \textit{insider} setup of \cite{cardestprivacy} that we present as S4 makes the strongest assumptions about the adversarial capabilities since it assumes that the attacker has a perfect view on the sketch. %combines the knowledge of adversaries from S1 and S2.
%\kenny{Not really! Because S1 is actually quite unrealistic, as we will argue below.}

\begin{itemize}
\item[S1:] The adversary does not know the details of the HLL implementation but can access a copy of the HLL instance as an user. He can use the API to insert elements into this shadow sketch, get the cardinality estimate, and reset it to its native empty state. The attacker does not know the state of the targeted HLL sketch, meaning that he cannot query its cardinality estimation and does not have the list of elements previously inserted into it by other users.
\item[S2:] The adversary has access to the details of the HLL implementation, i.e., the adversary knows the number of buckets $2^n$ and the hash function $h$ in use, but is otherwise ``blind''. In particular, an S2 adversary does not have access to the values of the HLL cardinality estimate at any point in its attack. This kind of attack scenario is appropriate in the context of the port scanning attack of~\cite{portscanhll}.
\item[S3:] The adversary has access to the details of the HLL implementation, i.e., the adversary knows the number of buckets $2^n$ and the hash function $h$ in use. Additionally, it can access and interact with the sketch via an API provided by the sketch owner, allowing it to insert items into the HLL sketch and ask for the HLL's cardinality estimate at any point in time.
\item[S4:] The adversary has direct access to the HLL in use and all its internals, i.e., the number of buckets, the hash function $h$, and also the contents of each bucket in the HLL sketch \emph{at one specific point in time}, i.e.\ it is given a \emph{snapshot} of the sketch. It then causes chosen inputs to be inserted into the HLL sketch. An S4 adversary can compute a lower bound on the HLL cardinality estimate based on its snapshot and whatever it causes to be inserted into the HLL sketch during its attack (this is irrespective of whether its attack proceeds with input from other users being added to the HLL sketch in parallel with its attack or not; if it knows that there is no other input, then it can compute the \emph{exact} value of the HLL cardinality estimate at every point in its attack instead of a lower bound).
\end{itemize}

Scenarios S1 and S2 are presented as M2 and M1, respectively, in~\cite{hllvuln}. S3 is the \textit{external} attack scenario in~\cite{cardestprivacy}. S4 is a slightly weaker version of the \textit{insider} attack scenario in~\cite{cardestprivacy}, the difference being that an insider adversary in~\cite{cardestprivacy} has continuous access to the HLL sketch internals including all bucket values, while our adversary in S4 only has access to a snapshot of the HLL sketch internals at the start of its attack.

We start by highlighting the fact that S1 seems unrealistic in practice. In a networking application, the authors of~\cite{hllvuln} argue that the assumptions of S1 could be fulfilled if the attacker learns which machine is used to do the monitoring and buys the same device. It is possible that the provider uses a different salt/key per device, which would make any pre-computation irrelevant, and considerably weaken the attack presented in Section 3.2 of \cite{hllvuln}. If we consider that the devices are perfect copies, we show that it is actually possible for the attacker to learn the internals of the HLL sketch. Precisely, the attacker can recover some bits of interest in the hash of targeted items, and infer the knowledge given to the adversary under S2. To do so, the attacker can insert the item $x$ on an empty sketch, ask for the resulting cardinality, which we denote $c$, and solve:
\begin{eqnarray*}
    \alpha 2^{2n}(\sum_{j=1}^{2^n}2^{-c_j})^{-1}& = & c \\
    \Leftrightarrow log_2(c)-log_2(\alpha 2^{2n} - c2^n + c) &=& c_i
\end{eqnarray*}
to learn $c_i$. $\alpha$ is a constant, $2^n$ is known as the provider must explicitly tell the customer the expected error of the estimation, hence the number of buckets, and $i$ is an arbitrary value representing the index of the bucket $x$ is mapped to (recovering $i$ is not useful). As $c_i$ denotes the $i$ bucket's content, updated by the insertion of $x$, $c_i-1$ is (an approximation of) the number of leading zeros in the $l$ rightmost bits of $h(x)$, which is the information extracted from $h(x)$ and used by the adversary in his attack under S2, as we detail in Section~\ref{sec:attacks}. %the value of the updated estimator of the bucket $x$ was mapped to, and recover some bits of $h(x)$.
To summarize, we do not consider this scenario typical of HLL deployments, and even if such setup may be possible under certain circumstances, the attacker can infer the knowledge given in S2.

\mathilde{Do you think that we should mention the idea behind the attack of \cite{hllvuln} Section 3.2 ? As they explained in their emails "The attacker can then test and find elements that do not increase the HLL estimate on the shadow HLL and thus will unlikely increase the cardinality of the target HLL when inserted."}

Furthermore, we show that although~\cite{cardestprivacy} presents S3 (external adversary) and the stronger version of our S4 (insider adversary) as two separate scenarios, an S3 adversary can easily infer the knowledge given to our S4 adversary in its snapshot. Indeed, an adversary can easily recover the contents of each bucket in the sketch simply by analysing which inputs increase the cardinality estimate. To find the estimate held in a targeted bucket, the attacker gradually inserts items $x$ with an incrementing number of leading zeros in the $\ell$ rightmost bits of $h(x)$ whilst holding the $n$ bits determining the bucket index constant, until the cardinality estimate of the sketch increases. Once a change occurs, the attacker knows that the maximum number of leading zeros observed in that bucket was just updated to a value that can be recovered by looking at the last inserted item. This assumes the attacker has sufficient flexibility in its choice of inputs $x$ so that the relevant bit conditions on $h(x)$ can be forced. The attacker can determine all bucket contents with, in the worst case, $O(2^{n + \ell})$ pre-computation and $O(\ell \cdot 2^{n})$ insert and cardinality estimate queries, and needs about $n + \ell$ bits of flexibility assuming $h$ behaves like a random function. The pre-computation and query complexity required can be much less if the HLL sketch is only moderately loaded.

A version of this attack can be carried out to elevate an external adversary to a full-strength insider adversary as per~\cite{cardestprivacy} (instead of our slightly weaker S4 adversary), since it can simply be done repeatedly each time the external adversary wants to know the complete internals of the HLL sketch. Obvious optimisations can be carried out to reduce the query complexity each time the attack is run (since the bucket contents can only increase over time, some queries are redundant; moreover, the pre-computation is only needed once and is moderate given typical HLL parameters, e.g.\ $n+\ell = 32$).

Since the assumptions of S1 appear to us to be unrealistic and since an attacker can escalate from S3 to S4, we focus on scenarios S2 and S4 in what follows. We first present an attack in scenario S2, providing much stronger results than the corresponding attack of \cite{hllvuln} (in their equivalent scenario M1). We then use the additional information the adversary has access to in scenario S4 to make the attack even more powerful.

\subsection{Manipulating the HLL Cardinality Estimate}

\noindent\paragraph{Scenario S2} The adversary knows $h$ so it can adjust fields in the item $x$ it is trying to insert and keep only those for which the $\ell$ rightmost bits of $h(x)$ start with a one bit. In this case, the number of leading zero bits computed by the estimator of the destination bucket is always zero, so the estimator of this bucket is unlikely to be updated and the averaged approximate cardinality is likely to be left unchanged. For example, in the scenario of \cite{portscanhll}, the adversary could change the source port of its IP packet until it is satisfied with its hash value. Given sufficient flexibility in the input $x$, the adversary can insert many items into the HLL without increasing the cardinality markedly, by repeatedly sampling from the input domain.

\noindent\paragraph{Scenario S4} The adversary can adopt the same strategy as for S2, but make the attack more efficient and reduce the sampling requirements with the additional information available in this scenario (namely, the count values per bucket in the HLL sketch). So, it can allow some leading zero bits in the $\ell$ rightmost bits of $h(x)$ so long as this does not increase the current bucket estimate. In other words, if $h(x)$ is mapped to the $i$-th bucket with estimated cardinality $2^{c_i + 1}$ (because a value with $c_i$ leading zeroes was previously observed for this bucket), then, instead of the strict restriction of having a one bit in the first position in the $\ell$ rightmost bits of $h(x)$, the adversary is satisfied when there is a one bit in any of the first $c_i+1$ positions in this substring. In case the adversary hits an empty bucket (for which the estimator is 0), it must skip that bucket completely. Under these conditions, the estimators in the buckets are never updated, and there is no effect on the cardinality estimate made by HLL.  A special case arises when the HLL is completely empty at the beginning of the attack; here the adversary is forced to increase the estimate in at least one bucket, but with sampling this can obviously be done in such a way as to increase the HLL estimate to $2$ in a single bucket, leaving all the other buckets untouched.

\subsection{Impact}
We now evaluate the impact of the above attacks on the HLL cardinality estimate. We assume that $h$ is a ``good" hash function, so that each of the bits of $h(x)$ can be regarded as being independent and uniformly random.

In scenario S2, the adversary needs to craft two distinct candidates for $x$ on average to obtain a one bit at the first position in the $\ell$ rightmost bits of $h(x)$, thus successfully performing the attack for a single insertion. Assuming the adversary has $t$ bits of flexibility in its choice of inputs, the adversary can expect to ``hide''  $2^{t-1}$ distinct items without increasing the HLL cardinality estimate at all, under the assumption that all buckets in the HLL sketch already hold a value $c_i \ge 1$. On the other hand, if some buckets are empty (but the adversary does not know which ones in the blind setting of S2), then we may expect a moderate increase in the HLL cardinality estimator. In the worst case, when all buckets are initially empty, the cardinality estimate will increase from 0 to at most $\alpha2^{n+1}$ (regardless of the number of items the adversary inserts). Notice that in all cases, provided $t$ is large enough, the adversary can keep the cardinality estimate linear in the total number of buckets ($2^n$) while the expected value of the true cardinality, $2^{t-1}$, can be made as large as the adversary pleases.

In scenario S4, we compute the average work required of the adversary to find an input $x$ such that $h(x)$ meets the attack's requirements. Let us assume for the moment that $c_i \ge 1$ for all buckets $i$. Assume $h(x)$ is mapped to bucket $i$. The probability that $h(x)$ does not increase the estimator is the probability that the  rightmost $\ell$ bits of $h(x)$ have $c_i$ or less leading zeroes; this probability is equal to $1-\frac{1}{2^{c_i+1}}$ assuming $h$ behaves like a random function. Averaging over all $2^n$ buckets (and using the fact that the bucket choice is uniformly random since the bits of $h$ are independent and uniformly random), the probability that input $x$ does not increase the estimator is given by:
\begin{eqnarray*}
\sum_{i=1}^{2^n}\frac{1}{2^n} \cdot (1-\frac{1}{2^{c_i+1}}) & = & 1-\frac{1}{2}\cdot (\frac{1}{2^n}\cdot \sum_{i=1}^{2^n} {(2^{c_i})}^{-1}) \\
& = &1-(2H_c)^{-1} \\
\end{eqnarray*}
where $H_c$ is the harmonic mean of the counts $2^{c_1}, 2^{c_2}, \ldots, 2^{c_{2^n}}$.

%$P(h(x)$ does NOT update bucket $i| h(x)$ mapped to bucket $i)=P(h(x)$ has LESS than $c_i$ leading 0s$)=1-P(h(x)$ has strictly MORE than $c_i$ leading 0s$)=1-\frac{1}{2^{c_i+1}}$\\
%Across all buckets, the adversary does not update any estimate with probability $P=
%\sum_{i=1}^{2^n}P(h(x)$ mapped to bucket $i$ AND $h(x)$ does NOT update bucket $i) = \sum_{i=1}^{2^n}P(h(x)$ mapped to bucket $i)P(h(x)$ does NOT update bucket $i| h(x)$ mapped to bucket $i) = \sum_{i=1}^{2^n}\frac{1}{2^n} \times (1-\frac{1}{2^{c_i+1}}) = 1-\frac{1}{2}\times(\frac{1}{2^n}\times \sum_{i=1}^{2^n} {(2^{c_i})}^{-1}) = 1-\frac{1}{2}\times\frac{1}{H_c} = 1-(2H_c)^{-1}$, with $H_c$ the harmonic mean of the numbers $2^{c_1}, 2^{c_2}, ..., 2^{c_{2^n}}$.
So the adversary needs to craft on average $(1-(2H_c)^{-1})^{-1}$ distinct candidates for $x$ in order to insert a single candidate, and, given $t$ bits of flexibility in its choice of inputs, can expect to ``hide" up to $(1-(2H_c)^{-1}) \cdot 2^t$ distinct items without increasing the HLL cardinality estimate at all.

%\textit{NOTE: does it take into account the special case of empty bucket ? counters are initialised to $c_i=-oo$ (or -1 in the code???) thus $P(h(x)$ has LESS than $-oo$ leading $0s) = 0$ but it is hard to add it to the probabilities while staying clear.}\\
%2$^{len(h(x))}\times \frac{2H_c-1}{H_c}$ items into the sketch.\\

Note that the above analysis for scenario S4 made the assumption that every bucket count $c_i$ was already at least 1. When some bucket counts are 0, the above analysis needs to be modified in order to avoid touching those buckets altogether. The modified analysis is quite straightforward. Suppose $r \le 2^n-1$ out of $2^n$ buckets have a count of zero. Then the cost of crafting an input $x$ becomes $(1-(2H_c)^{-1})^{-1} \cdot (1- \frac{r}{2^n})^{-1}$ trials, while the total number of items the adversary can expect to insert without increasing the HLL cardinality estimate becomes $(1-(2H_c)^{-1}) \cdot (1- \frac{r}{2^n})\cdot 2^t$. Of course, the adversary can relax its attack and allow some of the empty buckets to be hit. This increases the insertion rate at the cost of a small increase in the final cardinality estimate.

We assumed so far that there are already values coming from other honest users' data in the HLL. We now remove this assumption and instead assume that the HLL sketch is empty at the beginning of our attacks. The blind adversary in scenario S2 has no way to detect that it is attacking an empty HLL and cannot adapt its strategy, so all buckets that are hit will update their estimator once to $2^{0+1}=2$ items, leading to a worst-case final cardinality estimate of $\alpha2^{n+1}$ regardless of the number of items the adversary inserts. However, the adversary in S4 is able to detect that all buckets are empty and can adapt its attack accordingly. The adversary can now target and fill a single bucket only. This requires fixing $n+1$ bits of $h(x)$ for each input $x$, allowing the adversary to ``hide'' $2^{t-n-1}$ elements while keeping the HLL cardinality estimate to 1. Other trade-offs between work and the cardinality estimate are of course possible in scenario S4.

In both scenarios S2 and S4, we see that an adversary who has $t$ bits of flexibility in its inputs can expect to insert exponentially (in $t$) many inputs values into the HLL sketch without increasing the cardinality estimate (or whilst increasing the cardinality estimate slightly in the cases where the HLL sketch has empty buckets in S2 or where the HLL sketch is empty to begin with in S2 and S4). The result is largely independent of the HLL parameters, but does depend on the extent to which the HLL sketch is already filled, via a factor $1-(2H_c)^{-1}$ and the number of empty buckets $r$, via a factor $1- \frac{r}{2^n}$.


\subsection{Experimental Results}
Many different implementations of HLL are available online. Among the repositories collecting more than 350 stars on GitHub, we can cite~\cite{clahll} and~\cite{datasketch}. HLL is also featured in many frameworks, including Redis \cite{redis}, Google's BigQuery~\cite{bigquery}, Facebook's Airlift~\cite{airlift} and several products of Apache such as Spark~\cite{spahll} and Druid~\cite{druhll}. It is interesting to point out that all these implementations use a constant number of buckets and a fixed hash function. Thus they are vulnerable to our attacks in scenarios S2 and S4.

As a proof-of-concept, we implemented our attacks against the HLL implementation from~\cite{clahll}. The attack code is available at \href{https://github.com/PizzaWhisperer/HLLVuln}{\textit{\url{https://github.com/PizzaWhisperer/HLLVuln}}}. For simplicity, our items are 4-character long ASCII strings, giving us up to $7,311,616= 2^{22.8}$ distinct items that can be inserted (hence we have $t=22.8$ in our attacks). We choose $h$ to be the 32-bit Murmur3 hash function from \cite{murmur3code} (note that the library allows the hash function to be specified; we pick Murmur3 for our attack and consider it reasonable that the adversary should know the hash function in use).
% \kenny{Why do we get to choose $h$? Isn't it fixed by the specific implementation we are attacking?} \mathilde{The library has a place holder for a 32 bit hash function but lets the user choose it. This was one of my concerns and I was wondering if it would make sense to attack \cite{datasketch} instead (hardcoded $h$, but when we discussed it, you said that due to Kerckhoff's principle, this hash function should be public so it does not matter that much.}
We create an HLL sketch using $2^n = 256$ buckets and initialise it with 1,000 random items representing honest users' data.

We then challenge the adversary to pick the largest possible number of items to add to the sketch from our set of  $7,311,616$ possible inputs while trying to keep the cardinality estimate as low as possible, either in the S2 or the S4 scenario. As a second experiment, and in order to get results that can be compared to the work of~\cite{hllvuln}, we mounted our attack in their more restrictive setting: instead of picking from the universe of possible strings, the adversary has to choose what to insert from a set of 250,000 random items that are given to it. Finally, for completeness, we also run the attacks against HLL sketches that are initially empty. All attacks were run 30 times and the outcomes averaged. Our results are reported in Tables~\ref{table:tab1} and~\ref{table:tab2}, which detail the estimated cardinality at the beginning of the attack, the number of items added by the adversary, and the cardinality estimate after adding the adversary's items.

These empirical results confirm our impact analysis on several points.

First, when attacking a sketch already containing some items, we can see that the adversary is on average able to hide about half of the items in our starting set under S2 (as predicted by our theoretical analysis), and about 83\% under S4. %( $205$'$000 \approx 250'000 \times 0.82 \approx 250$'$000\times(1-\frac{1}{2\times H_c})$, with $H_c\approx\frac{1'000}{256}=3.9$)
Here $0.83 \approx (1-\frac{1}{2\cdot H_c})$ with $H_c\approx\frac{1000}{256}=3.9$, so the results are also consistent with our theoretical analysis.

Secondly, when attacking an empty HLL sketch in S2, the final cardinality estimate is always exactly $367=\alpha2^{n+1}$ with $\alpha = 0.72$ as specified by equation (29) in~\cite{hll}. For S4, the final cardinality estimate is always exactly 1 (this comes from rounding up the estimated cardinality of $\alpha = 0.72$ that arises from our attack targeting a single bucket). Note that in S4 with an initially empty HLL sketch, we insert (on average) 14,220 items into the sketch from our candidate set of $7,311,616$ items; this is again consistent with our theoretical predictions of $2^{t-n-1} = 2^{22.8-9} = 2^{13.8} = 14,263$. Of course, we could insert many more items into an initially empty HLL sketch in S4 by relaxing the single bucket restriction. This would come at the price of allowing the cardinality estimate to increase beyond 1.

We can also compare our results from Table~\ref{table:tab2} with results from the attack presented in Section 5.1 of~\cite{hllvuln}. In that paper, the authors target the Redis~\cite{redis} open-source implementation of HLL and perform the attack against an empty sketch. Given a set of 250,000 items, the adversary could choose ``74,390 distinct items and obtain an HLL estimate of only 15,780''~\cite{hllvuln}, achieving a five-fold reduction from the true cardinality. The authors present this attack as being in their M2 (our S1) scenario, without providing a detailed explanation. By looking at the Redis open-source code, we were able to obtain full details of the implementation that any attacker could obtain, and thus argue that based on this knowledge, the adversarial scenario is actually M1 (S2 in this work). This makes the comparison between the results of~\cite{hllvuln} and our S2 results appropriate. The S2 adversary following our strategy is able to add 125,000 distinct items while keeping the cardinality estimate at 367. Compared to~\cite{hllvuln}, we can insert twice as many items and reduce the cardinality estimate by a factor of 340 instead of 5.

\begin{table}[h]
\caption{Attack results, averaged over 30 iterations.}
\begin{tabular}{| m{8.5em} | m{4em} | m{4em} | m{4em} | m{4em} |}
    \hline
    \textbf{Scenario} & \multicolumn{2}{c|}{S2} & \multicolumn{2}{c|}{S4} \\ \hline
    \textbf{Initial data?} & yes & no & yes & no \\ \hline
    \textbf{Original Card. Est.} & 1,000 & 0 & 1,005 & 0 \\ \hline
    \textbf{\# Items added} & 3,655,744 & 3,655,740 & 6,090,003 & 14,220 \\ \hline
    \textbf{Final Card. Est.} & 1'011 & 367 & 1,005 & 1 \\ \hline
\end{tabular}
\label{table:tab1}
\end{table}

\begin{table}[h]
\caption{Attack results, averaged over 30 iterations, in the setting of \cite{hllvuln}.}
\begin{tabular}{| m{8.5em} | m{4em} | m{4em} | m{4em} | m{4em} |}
    \hline
    \textbf{Scenario} & \multicolumn{2}{c|}{S2} & \multicolumn{2}{c|}{S4} \\ \hline
    \textbf{Initial data?} & yes & no & yes & no \\ \hline
    \textbf{Original Card. Est.} & 1,004 & 0 & 998 & 0 \\ \hline
    \textbf{\# Items added} & 124,940 & 125,085 & 204,669 & 501 \\ \hline
    \textbf{Final Card. Est.} & 1,058 & 367 & 998 & 1 \\ \hline
\end{tabular}
\label{table:tab2}
\end{table}

\section{Conclusion}\label{sec:conclusions}
The HyperLogLog algorithm is an elegant and efficient solution to the problem of estimating the cardinality of large sets. Its simple structure makes it easy to code and use, as shown by the growing number of available open-source implementations. Nonetheless, malicious users can manipulate the HLL cardinality estimate and thence break the security properties of systems relying on HLL. Our attacks are simple but powerful and should raise awareness of the limitations of HLL. Our analysis may assist software developers in understanding the risks they run when using HLL in adversarial settings.

A formal analysis of using salting as a countermeasure to our attacks remains open.
%Future work could consist in finding mitigations that do not rely on salt. For example, would the imposed ID setting (like Facebook) solve the issue but still be convenient for the various HLL applications?
Also left for future work is the task of extending our attacks to HLL variants such as HLL++~\cite{hllpratice} and sliding HLL~\cite{slidinghll}.

\bibliographystyle{ieeetr}
\bibliography{ref.bib}

\end{document}
